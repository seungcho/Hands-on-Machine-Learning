{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHAPTER 7 앙상블 학습과 랜덤포레스트\n",
    "- 결정 트리의 앙상블을 랜덤포레스트라 하며 오늘날 가장 강력한 머신러닝 모델 중 하나이다.\n",
    "- 프로젝트의 마지막에 이미 만든 여러 괜찮은 예측기를 연결하여 더 좋은 예측기를 만든다.\n",
    "![test](./img/앙상블1.png)\n",
    "- 더 좋은 분류기를 만드는 매우 간단한 방법은 각 분류기의 예측을 모아서 가장 많이 선택된 클래스를 예측하는 것이다. (즉, 여러 예측기를 통해 다수결 투표를 하여 가장 많이 선택된 클래스를 채택한다.)\n",
    "![test](./img/다수결투표.png)\n",
    "- 이 다수결 투표 분류기가 앙상블에 포함된 개별 분류기 중 가장 뛰어난 것보다도 높은 경우가 많다.\n",
    "- 앙상블 방법은 예측기가 가능한 서로 독립적일 때 최고의 성능을 발휘 한다.\n",
    "> - 같은 데이터로 훈련시키기 때문에 같은 종류의 오차를 만들기 쉽다. 따라서 잘못된 클래스가 다수인 경우가 많고 앙상블의 정확도가 낮아진다.\n",
    "- 다양한 분류기를 얻는 한 가지 방법은 각기 다른 알고리즘으로 학습시키는 것이다. \n",
    "> - 이렇게 하면 매우 다른 종류의 오차를 만들 가능성이 높기 때문에 앙상블 모델의 정확도를 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42) # moon data_set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression() # LogisticRegression\n",
    "rnd_clf = RandomForestClassifier() # RandomForestClassifier\n",
    "svm_clf = SVC() # SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)), ('rf', RandomF...,\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(estimators=[('lr',log_clf),\n",
    "                                        ('rf',rnd_clf),\n",
    "                                        ('svc',svm_clf),\n",
    "                                        ],voting='hard') # model create\n",
    "voting_clf.fit(X_train,y_train) # model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.896\n",
      "SVC 0.888\n",
      "VotingClassifier 0.888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "for clf in (log_clf,rnd_clf,svm_clf,voting_clf):\n",
    "    clf.fit(X_train,y_train) \n",
    "    y_pred = clf.predict(X_test) # Performance check\n",
    "    print(clf.__class__.__name__,accuracy_score(y_test,y_pred)) # score check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예상대로 투표기반 분류기가 다른 개별 분류기보다 성능이 조금 더 높다.\n",
    "---------\n",
    "- 모든 분류기가 클래스의 확률을 예측할 수 있으면 (즉, predict_proba() 메서드가 있다면), 개별 분류기의 예측을 평균 내어 확률이 가장 높은 클래스를 예측할 수 있다. 이를 __간접 투표__라 한다.\n",
    "- 이 방식은 확률이 높은 투표에 비중을 더 두기 때문에 직접 투표 방식 보다 성능이 높다.\n",
    "> - voting = \"soft\"로 바꾸고 모든 분류기가 클래스의 확률을 추정할 수 있으면 된다.\n",
    "> - SVC는 클래스의 확률을 제공하지 않으므로 probability 매개변수를 True로 지정해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)), ('rf', RandomF...',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression() # LogisticRegression\n",
    "rnd_clf = RandomForestClassifier() # RandomForestClassifier\n",
    "svm_clf = SVC(probability=True) # SVM\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('lr',log_clf),\n",
    "                                        ('rf',rnd_clf),\n",
    "                                        ('svc',svm_clf),\n",
    "                                        ],voting='soft') # soft voting\n",
    "voting_clf.fit(X_train,y_train) # model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.872\n",
      "SVC 0.888\n",
      "VotingClassifier 0.904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf,rnd_clf,svm_clf,voting_clf):\n",
    "    clf.fit(X_train,y_train) \n",
    "    y_pred = clf.predict(X_test) # Performance check\n",
    "    print(clf.__class__.__name__,accuracy_score(y_test,y_pred)) # score check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 91%의 정확도를 얻음을 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 배깅과 페이스팅\n",
    "- 같은 알고리즘을 사용하지만 훈련 세트의 서브셋을 무작위로 구성하여 분류기를 각기 다르게 학습시키는 방법이 있다.\n",
    "> - ~~직접투표방식과 간접투표방식은 각기 다른 훈련 알고리즘을 사용하였다.~~\n",
    "- 훈련 세트에서 중복을 허용하여 샘플링하는 방식을 __배깅(bootstrap aggregating)__\n",
    "- 중복을 허용하지 않고 샘플링하는 방식을 __페이스팅(pasting)__\n",
    "> - 다시말해 배깅과 페이스팅에서는 같은 훈련 샘플을 여러 개의 예측기에 걸쳐 사용할 수 있다.\n",
    "> - 배깅만 한 예측기를 위해 같은 훈련 샘플을 여러 번 샘플링 할 수 있다.\n",
    "\n",
    "![test](./img/배깅.png)\n",
    "\n",
    "- 모든 예측기가 훈련을 마지면 앙상블은 모든 예칙기의 예측을 모아서 새로운 샘플에 대한 예측을 만든다.\n",
    "- 수집함수는 전형적으로 분류일 때는 통계적 최빈값 (즉, 직접 투표 분류기처럼 가장 많은 예측 결과)이고 회귀에 대해서는 평균을 계산한다.\n",
    "- 일반적으로 앙상블의 결과는 원본 데이터셋으로 하나의 예측기를 훈련시킬때와 비교해 비슷하지만 분산은 줄어든다. (분산이 줄어든다는 뜻은 그 만큼 과대적합에 위험에서 벗어난다는 뜻)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(),n_estimators=500,\n",
    "                           max_samples=100,bootstrap=True,n_jobs = -1)\n",
    "bag_clf.fit(X_train,y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- n_estimators = 500 : 500개의 트리 생성\n",
    "- max_samples = 100 : 한개의 트리당 100개의 샘플을 뽑는다.\n",
    "- bootstrap = True : 중복을 허용한 리샘플링\n",
    "- n_jobs = -1 : 가용가능한 모든 CPU 코어 수를 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred)) # 0.928"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](./img/배깅결정트리.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 앙상블의 예측이 결정 트리 하나의 예측보다 더 일반화가 잘 되었음을 알 수 있다.\n",
    "- 앙상블은 비슷한 평향에서 더 작은 분산을 만든다.\n",
    "> - 훈련세트의 오차 수가 거의 비슷하지만 결정 경계는 덜 불규칙하다.\n",
    "- 부스트래핑은 각 예측기가 학습하는 서브셋에 다양성을 증가시키므로 __배깅이 페이스팅보다 편향이 조금 높다.__ 하지만 이는 예측기들의 __상관관계를 줄이므로 앙상블의 분산을 감소__시킨다. 전반적으로 배깅이 더 나은 모델을 만들기 때문에 일반적으로 더 선호한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oob평가\n",
    "- 배깅을 사용하면 어떤 샘플은 한 예측기를 위해 여러 번 샘플링 되고 어떤 것은 전혀 선택되지 않을 수 있다. BaggingClassifer는 기본값으로 중복을 허용하여 (bootstrap=True) 훈련 세트의 크기 만큼인 m개의 샘플을 선택한다.\n",
    "- 이는 평균적으로 각 예측기에 훈련 샘플의 63% 정도만 샘플링된다는 것을 의미\n",
    "- 선택되지 않은 훈련 샘플의 나머지 37%를 oob(out of bag)샘플이라 부른다\n",
    "> - 예측기마다 남겨진 37%는 모두 다르다.\n",
    "- 예측기가 훈련되는 동안에는 oob 샘플을 사용하지 않으므로 검증 세트나 교차 검증을 사용하지 않고 oob 샘플을 사용해 평가할 수 있다. \n",
    "> - __앙상블의 평가는 각 예측기의 oob평가를 평균하여 얻는다.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8933333333333333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(),n_estimators = 500,\n",
    "                           bootstrap = True, n_jobs = -1, oob_score = True)\n",
    "bag_clf.fit(X_train,y_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- oob_score = True로 지정하면 훈련이 끝난 후 자동으로 oob평가를 수행\n",
    "- 즉, model을 훈련 시키는 동안 oob샘플은 훈련 대상에서 제외됨으로 oob샘플을 사용해 모델을 평가 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test,y_pred) # oob 샘플 점수와 비슷함을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3248731 , 0.6751269 ],\n",
       "       [0.34871795, 0.65128205],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.07954545, 0.92045455],\n",
       "       [0.36931818, 0.63068182],\n",
       "       [0.01470588, 0.98529412],\n",
       "       [0.98837209, 0.01162791],\n",
       "       [0.9895288 , 0.0104712 ],\n",
       "       [0.79081633, 0.20918367],\n",
       "       [0.01970443, 0.98029557],\n",
       "       [0.79329609, 0.20670391],\n",
       "       [0.85416667, 0.14583333],\n",
       "       [0.96      , 0.04      ],\n",
       "       [0.05263158, 0.94736842],\n",
       "       [0.        , 1.        ],\n",
       "       [0.97790055, 0.02209945],\n",
       "       [0.95555556, 0.04444444],\n",
       "       [0.99456522, 0.00543478],\n",
       "       [0.        , 1.        ],\n",
       "       [0.37288136, 0.62711864],\n",
       "       [0.90909091, 0.09090909],\n",
       "       [1.        , 0.        ],\n",
       "       [0.96685083, 0.03314917],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.66857143, 0.33142857],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.11173184, 0.88826816],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00520833, 0.99479167],\n",
       "       [0.35882353, 0.64117647],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.2716763 , 0.7283237 ],\n",
       "       [0.35638298, 0.64361702],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01104972, 0.98895028],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.87958115, 0.12041885],\n",
       "       [0.95238095, 0.04761905],\n",
       "       [0.96891192, 0.03108808],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02439024, 0.97560976],\n",
       "       [0.98787879, 0.01212121],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00526316, 0.99473684],\n",
       "       [0.9895288 , 0.0104712 ],\n",
       "       [0.7382199 , 0.2617801 ],\n",
       "       [0.37967914, 0.62032086],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00529101, 0.99470899],\n",
       "       [0.7       , 0.3       ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.88505747, 0.11494253],\n",
       "       [1.        , 0.        ],\n",
       "       [0.62436548, 0.37563452],\n",
       "       [0.13661202, 0.86338798],\n",
       "       [0.64971751, 0.35028249],\n",
       "       [0.88953488, 0.11046512],\n",
       "       [0.        , 1.        ],\n",
       "       [0.18781726, 0.81218274],\n",
       "       [0.92090395, 0.07909605],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99507389, 0.00492611],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02312139, 0.97687861],\n",
       "       [0.04371585, 0.95628415],\n",
       "       [0.31952663, 0.68047337],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.85164835, 0.14835165],\n",
       "       [0.01156069, 0.98843931],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.26373626, 0.73626374],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.96373057, 0.03626943],\n",
       "       [0.77717391, 0.22282609],\n",
       "       [0.01204819, 0.98795181],\n",
       "       [1.        , 0.        ],\n",
       "       [0.23076923, 0.76923077],\n",
       "       [0.65680473, 0.34319527],\n",
       "       [0.00555556, 0.99444444],\n",
       "       [0.04812834, 0.95187166],\n",
       "       [0.50531915, 0.49468085],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01129944, 0.98870056],\n",
       "       [1.        , 0.        ],\n",
       "       [0.18556701, 0.81443299],\n",
       "       [0.53191489, 0.46808511],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03076923, 0.96923077],\n",
       "       [0.9939759 , 0.0060241 ],\n",
       "       [0.27638191, 0.72361809],\n",
       "       [0.89772727, 0.10227273],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.80555556, 0.19444444],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01      , 0.99      ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99470899, 0.00529101],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.93922652, 0.06077348],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01212121, 0.98787879],\n",
       "       [0.25136612, 0.74863388],\n",
       "       [0.95652174, 0.04347826],\n",
       "       [0.285     , 0.715     ],\n",
       "       [0.99465241, 0.00534759],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00578035, 0.99421965],\n",
       "       [0.70918367, 0.29081633],\n",
       "       [0.41436464, 0.58563536],\n",
       "       [0.4137931 , 0.5862069 ],\n",
       "       [0.82795699, 0.17204301],\n",
       "       [0.93442623, 0.06557377],\n",
       "       [0.0625    , 0.9375    ],\n",
       "       [0.83333333, 0.16666667],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01666667, 0.98333333],\n",
       "       [0.97674419, 0.02325581],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01136364, 0.98863636],\n",
       "       [0.        , 1.        ],\n",
       "       [0.0052356 , 0.9947644 ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95287958, 0.04712042],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.40449438, 0.59550562],\n",
       "       [0.34895833, 0.65104167],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.28342246, 0.71657754],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99456522, 0.00543478],\n",
       "       [0.00561798, 0.99438202],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99479167, 0.00520833],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.63387978, 0.36612022],\n",
       "       [0.89444444, 0.10555556],\n",
       "       [0.        , 1.        ],\n",
       "       [0.9893617 , 0.0106383 ],\n",
       "       [0.99481865, 0.00518135],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.04938272, 0.95061728],\n",
       "       [1.        , 0.        ],\n",
       "       [0.05027933, 0.94972067],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02234637, 0.97765363],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94300518, 0.05699482],\n",
       "       [0.68862275, 0.31137725],\n",
       "       [0.61006289, 0.38993711],\n",
       "       [0.        , 1.        ],\n",
       "       [0.15384615, 0.84615385],\n",
       "       [1.        , 0.        ],\n",
       "       [0.91803279, 0.08196721],\n",
       "       [0.96571429, 0.03428571],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.43502825, 0.56497175],\n",
       "       [0.84736842, 0.15263158],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00485437, 0.99514563],\n",
       "       [0.00497512, 0.99502488],\n",
       "       [0.97      , 0.03      ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.25      , 0.75      ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98837209, 0.01162791],\n",
       "       [0.86592179, 0.13407821],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01570681, 0.98429319],\n",
       "       [0.08379888, 0.91620112],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02116402, 0.97883598],\n",
       "       [0.        , 1.        ],\n",
       "       [0.06976744, 0.93023256],\n",
       "       [1.        , 0.        ],\n",
       "       [0.79896907, 0.20103093],\n",
       "       [0.00561798, 0.99438202],\n",
       "       [0.92934783, 0.07065217],\n",
       "       [0.98342541, 0.01657459],\n",
       "       [0.16666667, 0.83333333],\n",
       "       [0.18090452, 0.81909548],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.20571429, 0.79428571],\n",
       "       [0.95604396, 0.04395604],\n",
       "       [0.00543478, 0.99456522],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.51470588, 0.48529412],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.09756098, 0.90243902],\n",
       "       [0.07106599, 0.92893401],\n",
       "       [0.98958333, 0.01041667],\n",
       "       [0.0052356 , 0.9947644 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.38333333, 0.61666667],\n",
       "       [0.12650602, 0.87349398],\n",
       "       [0.48663102, 0.51336898],\n",
       "       [0.59042553, 0.40957447],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00483092, 0.99516908],\n",
       "       [0.        , 1.        ],\n",
       "       [0.59659091, 0.40340909],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.26630435, 0.73369565],\n",
       "       [0.84042553, 0.15957447],\n",
       "       [0.08888889, 0.91111111],\n",
       "       [1.        , 0.        ],\n",
       "       [0.80838323, 0.19161677],\n",
       "       [0.        , 1.        ],\n",
       "       [0.005     , 0.995     ],\n",
       "       [0.14285714, 0.85714286],\n",
       "       [0.03977273, 0.96022727],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.90810811, 0.09189189],\n",
       "       [0.14736842, 0.85263158],\n",
       "       [0.93264249, 0.06735751],\n",
       "       [0.        , 1.        ],\n",
       "       [0.53293413, 0.46706587],\n",
       "       [0.05641026, 0.94358974],\n",
       "       [0.98913043, 0.01086957],\n",
       "       [0.7967033 , 0.2032967 ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.93658537, 0.06341463],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.33522727, 0.66477273],\n",
       "       [0.99435028, 0.00564972],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.87777778, 0.12222222],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.80107527, 0.19892473],\n",
       "       [0.92352941, 0.07647059],\n",
       "       [1.        , 0.        ],\n",
       "       [0.69417476, 0.30582524],\n",
       "       [0.52331606, 0.47668394],\n",
       "       [0.00581395, 0.99418605],\n",
       "       [0.91712707, 0.08287293],\n",
       "       [0.00510204, 0.99489796],\n",
       "       [1.        , 0.        ],\n",
       "       [0.87845304, 0.12154696],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.75555556, 0.24444444],\n",
       "       [0.1       , 0.9       ],\n",
       "       [0.44318182, 0.55681818],\n",
       "       [0.27868852, 0.72131148],\n",
       "       [0.        , 1.        ],\n",
       "       [0.8556701 , 0.1443299 ],\n",
       "       [0.78712871, 0.21287129],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99431818, 0.00568182],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01204819, 0.98795181],\n",
       "       [0.96428571, 0.03571429],\n",
       "       [0.94475138, 0.05524862],\n",
       "       [1.        , 0.        ],\n",
       "       [0.50555556, 0.49444444],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01030928, 0.98969072],\n",
       "       [0.98918919, 0.01081081],\n",
       "       [0.01176471, 0.98823529],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95628415, 0.04371585],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03030303, 0.96969697],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01117318, 0.98882682],\n",
       "       [1.        , 0.        ],\n",
       "       [0.12626263, 0.87373737],\n",
       "       [0.0047619 , 0.9952381 ],\n",
       "       [0.00505051, 0.99494949],\n",
       "       [0.        , 1.        ],\n",
       "       [0.42783505, 0.57216495],\n",
       "       [0.03061224, 0.96938776],\n",
       "       [0.28078818, 0.71921182],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98445596, 0.01554404],\n",
       "       [0.21176471, 0.78823529],\n",
       "       [0.99459459, 0.00540541],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00520833, 0.99479167],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94382022, 0.05617978],\n",
       "       [0.36263736, 0.63736264],\n",
       "       [0.99444444, 0.00555556],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00537634, 0.99462366],\n",
       "       [0.99009901, 0.00990099],\n",
       "       [0.        , 1.        ],\n",
       "       [0.04571429, 0.95428571],\n",
       "       [0.98550725, 0.01449275],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01578947, 0.98421053],\n",
       "       [0.59668508, 0.40331492]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_ # oob샘플에 대한 결정 함수 확인 [음성/양성]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 램덤 패치와 랜덤 서브스페이스\n",
    "- BaggingClassifier는 특정 샘플링도 지원한다.\n",
    "> - max_features: 최대 특성 선택\n",
    "> - bootstrap_feature: 랜덤 특성 선택\n",
    "- 따라서 각 예측기는 무작위로 선택한 입력 특성의 일부분으로 훈련된다.\n",
    "> 특히 이미지와 같은 매우 고차원의 데이터셋을 다룰 때 유용하다.\n",
    "- 훈련 특성과 샘플을 모두 샘플링 하는 것을 랜덤 패치 방식이라고 하고 훈련 샘플을 모두 사용(max_samples = 1.0)하고 특성은 샘플링하는 것을 랜덤 서브스페이스 방식이라 한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 랜덤 포레스트\n",
    "- 랜덤 포레스트는 배깅 방법을 적용한 결정트리의 앙상블이다. \n",
    "> - 전형적으로 max_samples를 훈련 세트의 크기로 지정\n",
    "> - Bagging에 Decision을 넣어 만드는 방법 대신 결정 트리에 최적하되어 사용하기 편리한 것이 랜덤포레스트 방법이다.\n",
    "- 랜덤 포레스트 알고리즘은 트리의 노드를 분할할 때 전체 특성 중에서 최선의 특성을 찾는 대신 무작위로 선택한 특성 후보 중에서 최적의 특성을 찾는 식으로 무작위성을 더 주입한다.\n",
    "> - 결국 트리를 더욱 다양하게 만들고 편향을 손해 보는 대신 분산을 낮추어 전체적으로 더 훌륭한 모델을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=16,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "rnd_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- n_estimatiors = 500은 500개의 tree 생성\n",
    "- max_leaf_nodes = 16 최대 16개의 리프노드를 갖는다.\n",
    "- n_jobs = -1 가용가는한 CPU 코어를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred) # oob 샘플 점수와 비슷함을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 특성의 중요도\n",
    "- 랜덤 포레스트의 또 다른 장점은 특성의 상대적 중요도를 측정하기 쉽다.\n",
    "> - 어떤 특성을 사용한 노드가 (랜덤 포레스트에 있는 모든 트리에 걸쳐서) 평균적으로 불순도를 얼마나 감소시키는지 확인하여 특성의 중요도를 측정한다.\n",
    "> - 더 정확히 말하면 가중치 평균이며 각 노드의 가중치는 연관된 훈련 샘플 수 와 같다.\n",
    ">> - 노드에 사용된 각 특성 별로(현재 노드의 샘플 비율 X 불순도) - (왼쪽 자식 노드의 샘플 비율 X 불순도) - (오른쪽 자식 노드의 샘플 비율 X 불순도)\n",
    ">> - 그 다음 특성 중요도 합이 1이 되도록 전체 합으로 나누어 정규화 한다.\n",
    ">> - 여기서 샘플 비율은 트리 전체 샘플 수에 대한 비율이다.\n",
    ">> - 랜덤 포레스트의 특성 중요도는 각 결정 트리의 특성 중요도를 모두 계산하여 더한 후 트리 수로 나눈 것이다.\n",
    "> - 사이킷런은 훈련이 끝난 뒤 특성마다 자동으로 이 점수를 계산하고 중요도의 전체 합이 1이 되도록 결괏값을 정규화 한다.\n",
    ">> - 이 값은 feature_importances_ 변수에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500,n_jobs=-1)\n",
    "rnd_clf.fit(iris['data'], iris['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.09430277497419999\n",
      "sepal width (cm) 0.022392526346413304\n",
      "petal length (cm) 0.4427560086400761\n",
      "petal width (cm) 0.4405486900393108\n"
     ]
    }
   ],
   "source": [
    "for name, score in zip (iris['feature_names'],rnd_clf.feature_importances_):\n",
    "    print(name, score) # petal, length가 핸덤 포레스트 모델을 훈련 시킴에 있어서 중요한 특성이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 부스팅\n",
    "- 부스팅(boosting)은 약한 학습기를 여러 개 연결하여 강한 학습기를 만드는 앙상블 방법을 말한다.\n",
    "- 부스팅 방법의 아이디어는 앞의 모델을 보완해나가면서 일련의 예측기를 학습시키는 것이다.\n",
    "\n",
    "## 아다부스트(AdaBoost)\n",
    "- 이전 예측기를 보완하는 새로운 예측기를 만드는 방법은 이전 모델이 과소적합했던 훈련 샘플의 가중치를 더 높이는 것이다.\n",
    "- 이렇게 하면 새로운 예측기는 학습하기 어려운 샘플에 점점 더 맞춰지게 된다.\n",
    "![test](./img/아다부스트.png)\n",
    "- 첫 번째 분류기 훈련세트에서 훈련을 시키고 예측을 만드는데 잘못 분류된 훈련 샘플의 가주치를 상대적으로 높여 다음 두 번째 분류기는 업데이트된 가중치를 사용해 훈련 세트에서 훈련하고 예측을 만들고 다시 가중치를 업데이트 하는 식으로 계속된다.\n",
    "- 연속된 학습 기법에는 중요한 단점이 하나 있다. 각 예측기는 이전 예측기가 훈련되고 평가된 후에 학습 될 수 있기 때문에 병렬화를 할 수 없다. 결국 배깅이나 페이스팅 만큼 확정성이 높지 않다.\n",
    "> - 사이킷런은 SAMME라는 아다부스트 다중 클래스 버전을 시용한다. 클래스가 두 개 뿐일 때는 SAMME가 아다부스트와 동일하다.\n",
    "> - 예측기가 클래스의 확률을 추정할 수 있다면(즉, predict_proba()메서드가 있다면) 사이킷런은 SAMME.R이라는 SAMME의 변종을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "          learning_rate=0.5, n_estimators=200, random_state=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),n_estimators=200,\n",
    "                            algorithm='SAMME.R',learning_rate=0.5)\n",
    "ada_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ada = ada_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 200개의 얕은 결정 트리를 기반으로 분류기를 훈련시킨다.\n",
    "- max_depth = 1 은 결정 노드 하나와 리프 노드 두개로 이루어진 트리이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그래디언트 부스팅\n",
    "- 인기가 높은 또 하나의 부스팅 알고리즘은 그래디언트 부스팅이다. \n",
    "- 아다부스트처럼 그래디언트 부스팅은 앙상블에 이전까지의 오차를 보정하도록 예측기를 순차적으로 추가한다. \n",
    "> - 하지만 아다부스트처럼 반복마다 샘플의 가중치를 수정하는 대신 이전 예측기가 만든 잔여 오차(residual error)에 새로운 예측기를 학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) - 0.5\n",
    "y = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_reg1 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg1.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = y - tree_reg1.predict(X)\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg2.fit(X,y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 첫 번째 예측기에서 생긴 잔여 오차에 두 번째 DecisionTreeRegressor을 훈련시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=2, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3 = y2 - tree_reg2.predict(X)\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg3.fit(X,y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다음 두 번째 예측기가 만든 잔여 오차에 세 번째 회귀 모델을 훈련시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[0.8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1,tree_reg2,tree_reg3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75026781])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이제 세 개의 트리를 포함하는 앙상블 모델이 생겼다.\n",
    "- 새로운 샘플에 대한 예측을 만들려면 모든 트리의 예측을 더하면 된다.\n",
    "\n",
    "![test](./img/그래디언트부스팅.png)\n",
    "\n",
    "- 왼쪽 열은 이 세 트리의 예측이고 오른쪽 열은 앙상블의 예측이다.\n",
    "> - 첫 번째 행에서는 앙상블에 트리가 하나만 있어서 첫 번째 트리의 예측과 완전히 같다.\n",
    "> - 두 번째 행에서는 새로운 트리가 첫 번째 트리의 잔여 오차에 대해 학습되었다.\n",
    ">> - 오른쪽의 앙상블 예측이 두 개의 트리 예측의 합과 같은 것을 볼 수 있다.\n",
    "> - 비슷하게 세 번째 행에서는 또 다른 트리가 두 번째 트리의 잔여 오차에 훈련되었다.\n",
    "> - 트리가 앙상블에 추가될수록 앙상블의 예측이 점차 좋아지는 것을 알 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingRegressor(max_depth=2,n_estimators=3,learning_rate=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- max_depth: 트리의 최대 깊이\n",
    "- n_estimators: 트리 수\n",
    "- learning_rate: 각 트리의 기여 정도를 조절\n",
    "> - 0.1처럼 낮게 설정하면 앙상블을 훈련 세트에 학습시키기 위해 많은 트리가 필요하지만 일반적으로 예측의 성능은 좋아진다. 이는 축소라고 부르는 규제 방법이다.\n",
    "\n",
    "![test](./img/앙상블.png)\n",
    "\n",
    "- 작은 학습률로 훈련 시킨 두 개의 앙상블이다.\n",
    "> - 왼쪽은 훈련 세트를 학습하기에는 트리가 충분하지 않고 오른쪽은 트리가 너무 많아 훈련 세트에 과대적합되었다.\n",
    "- 최적의 트리 수를 찾기 위해서는 조기 종료 기법(4장)을 사용할 수 있다. \n",
    "> - 간단하게 구현하려면 staged_predict() 메서드를 사용한다. \n",
    ">> - 이 메서드는 훈련의 각 단계 (트리 하나, 트리 두 개 등)에서 앙상블에 의해 만들어진 예측기를 순회하는 반복자(iterator)를 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) - 0.5\n",
    "y = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=2, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=120, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbrt = GradientBoostingRegressor(max_depth=2,n_estimators=120)\n",
    "gbrt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [mean_squared_error(y_val,y_pred) for y_pred in gbrt.staged_predict(X_val)]\n",
    "bst_n_estimators = np.argmin(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=2, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=67, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbrt_best = GradientBoostingRegressor(max_depth=2,n_estimators=bst_n_estimators)\n",
    "gbrt_best.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](./img/튜닝.png)\n",
    "\n",
    "- 많은 수의 트리를 먼저 훈련시키고 최적의 수를 찾기 위해 살펴보는 대신 실제로 훈련을 중지하는 방법으로 조기 종료를 구현할 수도 있다. warm_start = True를 설정하면 사이킷런이 fit() 메서드를 호출될 때 기존 트리를 유지하고 훈련을 추가할 수 있도록 도와준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True, random_state=42)\n",
    "\n",
    "min_val_error = float(\"inf\")\n",
    "error_going_up = 0\n",
    "for n_estimators in range(1, 120):\n",
    "    gbrt.n_estimators = n_estimators\n",
    "    gbrt.fit(X_train, y_train)\n",
    "    y_pred = gbrt.predict(X_val)\n",
    "    val_error = mean_squared_error(y_val, y_pred)\n",
    "    if val_error < min_val_error:\n",
    "        min_val_error = val_error\n",
    "        error_going_up = 0\n",
    "    else:\n",
    "        error_going_up += 1\n",
    "        if error_going_up == 5:\n",
    "            break  # early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    }
   ],
   "source": [
    "print(gbrt.n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum validation MSE: 0.0030248830463853182\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum validation MSE:\", min_val_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 연속해서 다섯 번의 반복 동안 검증 오차가 향상되지 않으면 훈련을 멈춘다.\n",
    "- 각 트리가 훈련할 때 사용할 훈련 샘플의 비율을 지정할 수 있는 subsample 매개변수도 지원한다.\n",
    "> - 예를들어 subsample = 0.25라고 하면 각 트리는 무작위로 선택된 25%의 훈련 샘플로 학습된다.\n",
    "> - 편향이 높아지는 대신 분산이 낮아지게 될 것이다. 또한 훈련 속도를 상당히 높인다. 이러한 기법을 확률적 그래디언트 부스팅이라 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import xgboost\n",
    "except ImportError as ex:\n",
    "    print(\"Error: the xgboost library is not installed.\")\n",
    "    xgboost = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 0.0031085575071820525\n"
     ]
    }
   ],
   "source": [
    "if xgboost is not None:  # not shown in the book\n",
    "    xgb_reg = xgboost.XGBRegressor(random_state=42)\n",
    "    xgb_reg.fit(X_train, y_train)\n",
    "    y_pred = xgb_reg.predict(X_val)\n",
    "    val_error = mean_squared_error(y_val, y_pred)\n",
    "    print(\"Validation MSE:\", val_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.270336\n",
      "Will train until validation_0-rmse hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-rmse:0.246844\n",
      "[2]\tvalidation_0-rmse:0.22505\n",
      "[3]\tvalidation_0-rmse:0.205587\n",
      "[4]\tvalidation_0-rmse:0.188344\n",
      "[5]\tvalidation_0-rmse:0.172722\n",
      "[6]\tvalidation_0-rmse:0.158756\n",
      "[7]\tvalidation_0-rmse:0.146858\n",
      "[8]\tvalidation_0-rmse:0.13578\n",
      "[9]\tvalidation_0-rmse:0.125776\n",
      "[10]\tvalidation_0-rmse:0.116912\n",
      "[11]\tvalidation_0-rmse:0.109149\n",
      "[12]\tvalidation_0-rmse:0.102133\n",
      "[13]\tvalidation_0-rmse:0.095785\n",
      "[14]\tvalidation_0-rmse:0.090162\n",
      "[15]\tvalidation_0-rmse:0.085444\n",
      "[16]\tvalidation_0-rmse:0.081195\n",
      "[17]\tvalidation_0-rmse:0.077256\n",
      "[18]\tvalidation_0-rmse:0.073665\n",
      "[19]\tvalidation_0-rmse:0.071101\n",
      "[20]\tvalidation_0-rmse:0.068513\n",
      "[21]\tvalidation_0-rmse:0.066321\n",
      "[22]\tvalidation_0-rmse:0.064664\n",
      "[23]\tvalidation_0-rmse:0.063302\n",
      "[24]\tvalidation_0-rmse:0.062233\n",
      "[25]\tvalidation_0-rmse:0.061267\n",
      "[26]\tvalidation_0-rmse:0.060281\n",
      "[27]\tvalidation_0-rmse:0.059617\n",
      "[28]\tvalidation_0-rmse:0.058976\n",
      "[29]\tvalidation_0-rmse:0.058426\n",
      "[30]\tvalidation_0-rmse:0.05799\n",
      "[31]\tvalidation_0-rmse:0.057546\n",
      "[32]\tvalidation_0-rmse:0.057239\n",
      "[33]\tvalidation_0-rmse:0.056949\n",
      "[34]\tvalidation_0-rmse:0.056829\n",
      "[35]\tvalidation_0-rmse:0.0567\n",
      "[36]\tvalidation_0-rmse:0.056553\n",
      "[37]\tvalidation_0-rmse:0.056393\n",
      "[38]\tvalidation_0-rmse:0.056291\n",
      "[39]\tvalidation_0-rmse:0.05621\n",
      "[40]\tvalidation_0-rmse:0.05613\n",
      "[41]\tvalidation_0-rmse:0.056136\n",
      "[42]\tvalidation_0-rmse:0.056044\n",
      "[43]\tvalidation_0-rmse:0.055995\n",
      "[44]\tvalidation_0-rmse:0.055915\n",
      "[45]\tvalidation_0-rmse:0.055884\n",
      "[46]\tvalidation_0-rmse:0.05582\n",
      "[47]\tvalidation_0-rmse:0.055711\n",
      "[48]\tvalidation_0-rmse:0.055717\n",
      "[49]\tvalidation_0-rmse:0.055818\n",
      "Stopping. Best iteration:\n",
      "[47]\tvalidation_0-rmse:0.055711\n",
      "\n",
      "Validation MSE: 0.0031036856672880114\n"
     ]
    }
   ],
   "source": [
    "if xgboost is not None:  # not shown in the book\n",
    "    xgb_reg.fit(X_train, y_train,\n",
    "                eval_set=[(X_val, y_val)], early_stopping_rounds=2)\n",
    "    y_pred = xgb_reg.predict(X_val)\n",
    "    val_error = mean_squared_error(y_val, y_pred)\n",
    "    print(\"Validation MSE:\", val_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 스태킹\n",
    "- 앙상블에 속한 모든 예측기의 예측을 취합하는 간단한 함수를 사용하는 대신 취합하는 모델을 훈련시킬 수 없을까? 라는 기본적인 아이디어에서 출발한다.\n",
    "- 스태킹(stacking, stacked generalization의 줄임)은 '1 - 투표 기반 분류기'에서 처럼 'hard voting', 'soft voting' 방법이 아니라 앙상블 학습에서 각 모델의 예측값을 가지고 새로운 메타 모델(meta learner)을 학습시켜 최종 예측 모델을 만드는 방법을 말한다.\n",
    "\n",
    "![test](./img/스태킹.png)\n",
    "\n",
    "- 블렌더를 학습시키는 일반적인 방법은 홀드 아웃 세트를 사용하는 것이다. \n",
    "- 먼저 훈련 세트를 두 개의 서브셋으로 나누고, 첫 번째 서브셋은 첫번째 레이어의 예측을 훈련 시키기 위해 사용된다.\n",
    "- 그런 다음 첫 번째 레이어의 예측기를 사용해 두 번째 세트 홀드 아웃 세트에 대한 예측을 만든다. 예측기들이 훈련하는 동안 이 샘플들을 전혀 보지 못했기 때문에 이때 만들어진 예측은 완전히 새로운 것이다. \n",
    "- 이제 홀드 아웃 세트의 각 샘플에 대해 세 개의 예측값이 만들어진다.\n",
    "- 타깃값은 그대로 쓰고 앞에서 예측한 값을 입력 특성으로 사용하는 사용하는 새로운 훈련 세트를 만들 수 있다. (새로운 훈련 세트는 3차원이 된다.) 블렌더가 새 훈련 세트로 훈련이 된다. 즉, 첫번째 레이어의 예측을 가지고 타깃값을 예측하도록 학습된다.\n",
    "\n",
    "스태킹(stacking)의 과정은 다음과 같다.\n",
    "\n",
    "- 학습 데이터셋에서 샘플링을 통해 서브셋1(subset-1)을 만들고, 이 서브셋을 이용해 각 모델을 학습시킨다. \n",
    "\n",
    "- 서브셋2(subset-2) 학습 시킨 모델을 이용해 각 모델의 예측값을 출력하고 예측값들을 합친다.\n",
    "\n",
    "- 합쳐진 예측값들을 입력 특성(input feature)로 사용하는 새로운 모델(meta learner, blender)을 학습시킨다.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
